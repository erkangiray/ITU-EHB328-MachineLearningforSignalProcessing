{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e05e080-5c98-485a-8ef0-891a95adaadb",
   "metadata": {},
   "source": [
    "# EHB328 - Birinci Odev Ikinci Kisim\n",
    "## Gauss Dagilimina Gore Veriyi Olusturmak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a721852-73ee-478d-a9d4-e62e827223a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math  as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0319e7c-4271-48a0-be35-148af480fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateGaussianData(N,aves,covs):\n",
    "    #gets number of features\n",
    "    #used in the rest of the code\n",
    "    no_of_features=np.size(aves)\n",
    "    \n",
    "    #av_holder=np.zeros(no_of_features)\n",
    "    # holds averages for features \n",
    "    #for i in loc:\n",
    "    #    av_holder=i\n",
    "    #since I decided to do each class separately\n",
    "    #I removed this part\n",
    "    \n",
    "    \n",
    "    std_dev_holder=np.zeros(no_of_features)\n",
    "    #holds standard deviations for features \n",
    "    for i in range(no_of_features):\n",
    "        std_dev_holder[i]=mt.sqrt(covs[i,i])\n",
    "        \n",
    "    #N sample size specified\n",
    "    #samples from Gaussian distribution\n",
    "    samples=np.zeros((N,no_of_features))\n",
    "    for i in range(N):\n",
    "        for l in range(no_of_features):\n",
    "            samples[i,l]=np.random.normal(aves[l],std_dev_holder[l])\n",
    "            \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c3f96c1-8cae-4266-9961-5d5c4bb5d5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution Parameters for first Class\n",
    "mean_c1=np.array([3,2])\n",
    "cov_c1=np.array([[0.5,0],[0,0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1047dee7-d626-462a-ad15-6d363b6e8d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want a hundred samples\n",
    "N=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cda3ce2-9570-451a-893d-bebb291c7820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample the Gaussian distribution \n",
    "#hundred times for the first class\n",
    "samples_c1=GenerateGaussianData(N,mean_c1,cov_c1)\n",
    "#print(samples_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b86e9f99-64b3-4afb-bfeb-e7087de4c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution Parameters for second class\n",
    "mean_c2=np.array([5,4])\n",
    "cov_c2=np.array([[1,0],[0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a06837e-6ea2-46d4-a88d-4d9cd3d28dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample Gaussian for the second class\n",
    "samples_c2=GenerateGaussianData(N,mean_c2,cov_c2)\n",
    "#print(samples_c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a853635-bf6d-49f1-b94a-0e85d7b829aa",
   "metadata": {},
   "source": [
    "## Ayirt Edici Fonksiyonu Tanimlamak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d6539c-def5-460b-a7b0-100f1914d3b9",
   "metadata": {},
   "source": [
    "P(C1)=P(C2) olarak siniflarin gelme olasiliklari birbirlerine esittir diye varsaydim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d2b83c-bf55-4c90-b509-f0edfeca72db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking each class to have equal probabilities\n",
    "P_C=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b190fe2b-24fd-4321-9255-8e9aa342770b",
   "metadata": {},
   "source": [
    "Her iki sinifin da kovaryans matrislerinin kosegen disi elemanlarini sifir oldugu icin ders notlarindaki ayirt edici fonksiyonu (discriminant function) kullandim. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b520c71-f240-4997-9278-3c5b29514b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminant_fnc(data_2_predict,ave,cov_matrix,N,P_C):\n",
    "    # data to predict, expected: 1x2 real number array\n",
    "    # new data to classify\n",
    "    # two elements for each feature\n",
    "    \n",
    "    # ave, expected: 1x2 real number array\n",
    "    # expecting input \"mean_cx\" variables\n",
    "    # distribution parameter\n",
    "    \n",
    "    # cov_matrix, expected: 2x2 real number array\n",
    "    # expecting input \"cov_cx\" variables\n",
    "    # distribution parameter\n",
    "    \n",
    "    # calculate inverse of cov_matrix\n",
    "    inv_cov=np.linalg.inv(cov_matrix)\n",
    "    \n",
    "    # calculate x - averages, \n",
    "    # operation: 1x2 - 1x2, result: 1x2\n",
    "    temp = data_2_predict - ave\n",
    "    \n",
    "    # calculate transpose of x - averages\n",
    "    # result : 2x1\n",
    "    transposed_temp = np.reshape(temp,(2,1))\n",
    "    \n",
    "    # calculate x . cov^-1\n",
    "    dot_temp = np.dot( temp , inv_cov )\n",
    "    # calculate (x . cov^-1) . xT\n",
    "    dot_temp = np.dot( dot_temp, transposed_temp )\n",
    "    # calculate -1/2 * (x-av) . cov^-1 . (x-av)^T\n",
    "    dot_pdt = -1/2 * dot_temp\n",
    "    \n",
    "    # calculate -1/2*N*ln|cov|\n",
    "    # log of covariance matrix times Number of examples\n",
    "    log_cov = (-1/2)*N*(np.log(cov_matrix))\n",
    "    # not sure if abs must be used\n",
    "    \n",
    "    # calculate log(Pi),\n",
    "    # log of prior probability of class\n",
    "    log_prob = np.log(P_C)\n",
    "    \n",
    "    g = dot_pdt + log_cov + log_prob\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33bfdd6-8af7-454f-91c3-ec1e6c862cc9",
   "metadata": {},
   "source": [
    "### discriminant_fnc() Tanimlamasi\n",
    "<b>discriminant_fnc() parametreleri:</b>\n",
    "<br><i>&emsp;data_2_predict:</i><br>\n",
    "&emsp;&ensp;siniflandirmasi yapilacak veri vektoru\n",
    "<br><i>&emsp;ave:</i><br>\n",
    "&emsp;&ensp;ozniteliklere ait dagilimin ortalama vektoru\n",
    "<br><i>&emsp;cov_matrix:</i><br>\n",
    "&emsp;&ensp;ozniteliklere ait dagilimin ortalama vektoru\n",
    "<br><i>&emsp;N:</i><br>\n",
    "&emsp;&ensp;ornek sayisi (example)\n",
    "<br><i>&emsp;P_C:</i><br>\n",
    "&emsp;&ensp;siniflara ait onsel olasilik, P(Ci)\n",
    "<br><br><b>discriminant_fnc() aciklamasi:</b>\n",
    "Mevucut olan siniflardan birine ait dagilim degerleri girilir.\n",
    "O sinifa ait ayirt edici fonksiyonun degeri girilen oznitelik vektorune gore hesaplanir.\n",
    "<br><br><b>kullanilan fonksiyonlar:</b>\n",
    "<br><i>&emsp;np.linalg.inv():</i> bir matrisin eleman tersini elde eder.\n",
    "<br><i>&emsp;np.reshape():</i> ic carpimda kullanilmak uzere verilen vektorun<br>&emsp;transpozunu elde eder.\n",
    "<br><i>&emsp;np.dot():</i> GPU'dan yararlanarak ic carpim islemini gerceklestirir.\n",
    "<br><i>&emsp;np.log():</i> giris uzerinde dogal logaritma islemini gerceklestirir.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f754db46-533e-4016-9538-e5005e6a35d7",
   "metadata": {},
   "source": [
    "<b>Not:</b> Kovaryans matrisleri birbirlerine esit olmadigi icin bir sonraki paragrafta ekledigim Vikipedi baglantilarindaki fonksiyonlari kullanmam gerektigini dusunmustum. Fakat o sayfalarda da bahsettigi uzere asil yapilan islem sonsal olasik dagilimi (P(C|x)) kullanilarak secim yapilmasi. Bu sebeple ders notlarindaki fonksiyonu kullanarak hata yapmadigimi dusunuyorum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8eeaf9-3145-431b-9837-6c60b5dad0e1",
   "metadata": {},
   "source": [
    "Quadratic discriminant analysis (QDA) is closely related to linear discriminant analysis (LDA), where it is assumed that the measurements from each class are normally distributed. Unlike LDA however, in QDA there is no assumption that the covariance of each of the classes is identical. When the normality assumption is true, the best possible test for the hypothesis that a given measurement is from a given class is the likelihood ratio test.\n",
    "https://en.wikipedia.org/wiki/Linear_discriminant_analysis\n",
    "https://en.wikipedia.org/wiki/Quadratic_classifier#Quadratic_discriminant_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f32d0d1-ee6d-483e-ad25-e518656a7b48",
   "metadata": {},
   "source": [
    "## Siniflandirici Tanimlamak\n",
    "\n",
    "Karar verici fonksiyon ayni veriyi kullanarak iki sinifa da ait olan ayirt edici fonksiyonlari ayri ayri cagirarak, verinin hangi sinifa ait olduguna karar verir. Hangi sinifa ait ayirt edici fonksiyonun geri getirdigi g degeri daha yuksekse verinin o sinifa ait olduguna karar verilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dd783a-56b8-48ae-ba62-63e9feafc099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classify():\n",
    "    \n",
    "return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa10e26-1188-461b-a5fb-bd2b2a434d4f",
   "metadata": {},
   "source": [
    "Simdi onceki bolumde urettigimiz verinin hepsi icin karar verici fonksiyonu cagiracagiz."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
