{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e05e080-5c98-485a-8ef0-891a95adaadb",
   "metadata": {},
   "source": [
    "# EHB328 - Birinci Odev Ikinci Kisim\n",
    "## Gauss Dagilimina Gore Veriyi Olusturmak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a721852-73ee-478d-a9d4-e62e827223a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math  as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0319e7c-4271-48a0-be35-148af480fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateGaussianData(N,aves,covs):\n",
    "    #gets number of features\n",
    "    #used in the rest of the code\n",
    "    no_of_features=np.size(aves)\n",
    "    \n",
    "    #av_holder=np.zeros(no_of_features)\n",
    "    # holds averages for features \n",
    "    #for i in loc:\n",
    "    #    av_holder=i\n",
    "    #since I decided to do each class separately\n",
    "    #I removed this part\n",
    "    \n",
    "    \n",
    "    std_dev_holder=np.zeros(no_of_features)\n",
    "    #holds standard deviations for features \n",
    "    for i in range(no_of_features):\n",
    "        std_dev_holder[i]=mt.sqrt(covs[i,i])\n",
    "        \n",
    "    #N sample size specified\n",
    "    #samples from Gaussian distribution\n",
    "    samples=np.zeros((N,no_of_features))\n",
    "    for i in range(N):\n",
    "        for l in range(no_of_features):\n",
    "            samples[i,l]=np.random.normal(aves[l],std_dev_holder[l])\n",
    "            \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c3f96c1-8cae-4266-9961-5d5c4bb5d5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution Parameters for first Class\n",
    "mean_c1=np.array([3,2])\n",
    "cov_c1=np.array([[0.5,0],[0,0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1047dee7-d626-462a-ad15-6d363b6e8d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want a hundred samples\n",
    "N=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cda3ce2-9570-451a-893d-bebb291c7820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample the Gaussian distribution \n",
    "#hundred times for the first class\n",
    "samples_c1=GenerateGaussianData(N,mean_c1,cov_c1)\n",
    "#print(samples_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86e9f99-64b3-4afb-bfeb-e7087de4c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution Parameters for second class\n",
    "mean_c2=np.array([5,4])\n",
    "cov_c2=np.array([[1,0],[0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a06837e-6ea2-46d4-a88d-4d9cd3d28dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample Gaussian for the second class\n",
    "samples_c2=GenerateGaussianData(N,mean_c2,cov_c2)\n",
    "#print(samples_c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a853635-bf6d-49f1-b94a-0e85d7b829aa",
   "metadata": {},
   "source": [
    "## Ayirt Edici Fonksiyonu Tanimlamak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d6539c-def5-460b-a7b0-100f1914d3b9",
   "metadata": {},
   "source": [
    "P(C1)=P(C2) olarak siniflarin gelme olasiliklari birbirlerine esittir diye varsaydim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d2b83c-bf55-4c90-b509-f0edfeca72db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking each class to have equal probabilities\n",
    "P_C=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b190fe2b-24fd-4321-9255-8e9aa342770b",
   "metadata": {},
   "source": [
    "Her iki sinifin da kovaryans matrislerinin kosegen disi elemanlarini sifir oldugu icin ders notlarindaki ayirt edici fonksiyonu (discriminant function) kullandim. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8eeaf9-3145-431b-9837-6c60b5dad0e1",
   "metadata": {},
   "source": [
    "Quadratic discriminant analysis (QDA) is closely related to linear discriminant analysis (LDA), where it is assumed that the measurements from each class are normally distributed. Unlike LDA however, in QDA there is no assumption that the covariance of each of the classes is identical. When the normality assumption is true, the best possible test for the hypothesis that a given measurement is from a given class is the likelihood ratio test.\n",
    "https://en.wikipedia.org/wiki/Linear_discriminant_analysis\n",
    "https://en.wikipedia.org/wiki/Quadratic_classifier#Quadratic_discriminant_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f754db46-533e-4016-9538-e5005e6a35d7",
   "metadata": {},
   "source": [
    "<b>Not:</b> Kovaryans matrisleri birbirlerine esit olmadigi icin bir sonraki paragrafta ekledigim Vikipedi baglantilarindaki fonksiyonlari kullanmam gerektigini dusunmustum. Fakat o sayfalarda da bahsettigi uzere asil yapilan islem sonsal olasik dagilimi (P(C|x)) kullanilarak secim yapilmasi. Bu sebeple ders notlarindaki fonksiyonu kullanarak hata yapmadigimi dusunuyorum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b520c71-f240-4997-9278-3c5b29514b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminant_fnc(data_2_predict,ave,cov_matrix,N,P_C):\n",
    "    data_transposed=np.reshape(data_2_predict,(2,1))\n",
    "    dot_result=np.dot(data_2_predict-ave,cov_matrix)\n",
    "    intermediary=data_transposed-np.reshape(ave,(2,1))\n",
    "    dot_result=np.dot(dot_result,intermediary)\n",
    "    \n",
    "    g= (-1/2)*dot_result + (-1/2)*N*np.log(np.linalg.det(cov_matrix)) + np.log(P_C)\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f922a0cb-493a-4152-b326-834936aa00ff",
   "metadata": {},
   "source": [
    "\"np.reshape\" kullanilmasinin sebebi formulde oldugu sekliyle ic carpabilmektir. \"np\" kutuphanesi ile tanimladigimiz arrayler \"1x...\" seklinde oluyor. Ic carpimda ise \"1x2\"*\"2x2\"*\"2x1\" olmasi gerekiyor. Sonuncu \"2x1\" vektoru elde etmek icin averaj matrisini \"np.reshape\" ile tekrar sekillendiriyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f32d0d1-ee6d-483e-ad25-e518656a7b48",
   "metadata": {},
   "source": [
    "Karar verici fonksiyon ayni veriyi kullanarak iki sinifa da ait olan ayirt edici fonksiyonlari ayri ayri cagirarak, verinin hangi sinifa ait olduguna karar verir. Hangi sinifa ait ayirt edici fonksiyonun geri getirdigi g degeri daha yuksekse verinin o sinifa ait olduguna karar verilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa10e26-1188-461b-a5fb-bd2b2a434d4f",
   "metadata": {},
   "source": [
    "Simdi onceki bolumde urettigimiz verinin hepsi icin karar verici fonksiyonu cagiracagiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08b29ee-748a-4548-9a74-548034c0727b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
