{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e05e080-5c98-485a-8ef0-891a95adaadb",
   "metadata": {},
   "source": [
    "# EHB328 - Birinci Odev Ikinci Kisim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc251bd-4991-40d6-8f1d-92f942e64e84",
   "metadata": {},
   "source": [
    "## Gauss Dagilimina Gore Veriyi Olusturmak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a721852-73ee-478d-a9d4-e62e827223a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math  as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0319e7c-4271-48a0-be35-148af480fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateGaussianData(N,aves,covs):\n",
    "    #gets number of features\n",
    "    #used in the rest of the code\n",
    "    no_of_features=np.size(aves)\n",
    "    \n",
    "    #av_holder=np.zeros(no_of_features)\n",
    "    # holds averages for features \n",
    "    #for i in loc:\n",
    "    #    av_holder=i\n",
    "    #since I decided to do each class separately\n",
    "    #I removed this part\n",
    "    \n",
    "    \n",
    "    std_dev_holder=np.zeros(no_of_features)\n",
    "    #holds standard deviations for features \n",
    "    for i in range(no_of_features):\n",
    "        std_dev_holder[i]=mt.sqrt(covs[i,i])\n",
    "        \n",
    "    #N sample size specified\n",
    "    #samples from Gaussian distribution\n",
    "    samples=np.zeros((N,no_of_features))\n",
    "    for i in range(N):\n",
    "        for l in range(no_of_features):\n",
    "            samples[i,l]=np.random.normal(aves[l],std_dev_holder[l])\n",
    "            \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c3f96c1-8cae-4266-9961-5d5c4bb5d5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution Parameters for first Class\n",
    "mean_c1=np.array([3,2])\n",
    "cov_c1=np.array([[0.5,0],[0,0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1047dee7-d626-462a-ad15-6d363b6e8d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want a hundred samples\n",
    "N=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cda3ce2-9570-451a-893d-bebb291c7820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample the Gaussian distribution \n",
    "#hundred times for the first class\n",
    "samples_c1=GenerateGaussianData(N,mean_c1,cov_c1)\n",
    "#print(samples_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b86e9f99-64b3-4afb-bfeb-e7087de4c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution Parameters for second class\n",
    "mean_c2=np.array([5,4])\n",
    "cov_c2=np.array([[1,0],[0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a06837e-6ea2-46d4-a88d-4d9cd3d28dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample Gaussian for the second class\n",
    "samples_c2=GenerateGaussianData(N,mean_c2,cov_c2)\n",
    "#print(samples_c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a853635-bf6d-49f1-b94a-0e85d7b829aa",
   "metadata": {},
   "source": [
    "## Ayirt Edici Fonksiyonu Tanimlamak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d6539c-def5-460b-a7b0-100f1914d3b9",
   "metadata": {},
   "source": [
    "P(C1)=P(C2) olarak siniflarin gelme olasiliklari birbirlerine esittir diye varsaydim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6d2b83c-bf55-4c90-b509-f0edfeca72db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking each class to have equal probabilities\n",
    "P_C=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b190fe2b-24fd-4321-9255-8e9aa342770b",
   "metadata": {},
   "source": [
    "Her iki sinifin da kovaryans matrislerinin kosegen disi elemanlarini sifir oldugu icin ders notlarindaki ayirt edici fonksiyonu (discriminant function) kullandim. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b520c71-f240-4997-9278-3c5b29514b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminant_fnc(data_2_predict,ave,cov_matrix,N,P_C):\n",
    "    # data to predict, expected: 1x2 real number array\n",
    "    # new data to classify\n",
    "    # two elements for each feature\n",
    "    \n",
    "    # ave, expected: 1x2 real number array\n",
    "    # expecting input \"mean_cx\" variables\n",
    "    # distribution parameter\n",
    "    \n",
    "    # cov_matrix, expected: 2x2 real number array\n",
    "    # expecting input \"cov_cx\" variables\n",
    "    # distribution parameter\n",
    "    \n",
    "    # calculate inverse of cov_matrix\n",
    "    inv_cov=np.linalg.inv(cov_matrix)\n",
    "    \n",
    "    # calculate x - averages, \n",
    "    # operation: 1x2 - 1x2, result: 1x2\n",
    "    temp = data_2_predict - ave\n",
    "    \n",
    "    # calculate transpose of x - averages\n",
    "    # result : 2x1\n",
    "    transposed_temp = np.reshape(temp,(2,1))\n",
    "    \n",
    "    # calculate x . cov^-1\n",
    "    dot_temp = np.dot( temp , inv_cov )\n",
    "    # calculate (x . cov^-1) . xT\n",
    "    dot_temp = np.dot( dot_temp, transposed_temp )\n",
    "    # calculate -1/2 * (x-av) . cov^-1 . (x-av)^T\n",
    "    dot_pdt = -1/2 * dot_temp\n",
    "    \n",
    "    # calculate -1/2*N*ln|cov|\n",
    "    # log of covariance matrix times Number of examples\n",
    "    #log_cov = (-1/2)*N*(np.log(cov_matrix))\n",
    "    # not sure if abs must be used\n",
    "    \n",
    "    # calculate log(Pi),\n",
    "    # log of prior probability of class\n",
    "    log_prob = np.log(P_C)\n",
    "    \n",
    "    # I am not sure about incuding log_cov\n",
    "    #g = dot_pdt + log_cov + log_prob\n",
    "    \n",
    "    g = dot_pdt + log_prob\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33bfdd6-8af7-454f-91c3-ec1e6c862cc9",
   "metadata": {},
   "source": [
    "### discriminant_fnc() Tanimlamasi\n",
    "<b>discriminant_fnc() parametreleri:</b>\n",
    "<br><i>&emsp;data_2_predict:</i><br>\n",
    "&emsp;&ensp;siniflandirmasi yapilacak veri vektoru\n",
    "<br><i>&emsp;ave:</i><br>\n",
    "&emsp;&ensp;ozniteliklere ait dagilimin ortalama vektoru\n",
    "<br><i>&emsp;cov_matrix:</i><br>\n",
    "&emsp;&ensp;ozniteliklere ait dagilimin ortalama vektoru\n",
    "<br><i>&emsp;N:</i><br>\n",
    "&emsp;&ensp;ornek sayisi (example)\n",
    "<br><i>&emsp;P_C:</i><br>\n",
    "&emsp;&ensp;siniflara ait onsel olasilik, P(Ci)\n",
    "<br><br><b>discriminant_fnc() aciklamasi:</b>\n",
    "Mevucut olan siniflardan birine ait dagilim degerleri girilir.\n",
    "O sinifa ait ayirt edici fonksiyonun degeri girilen oznitelik vektorune gore hesaplanir.\n",
    "<br><br><b>kullanilan fonksiyonlar:</b>\n",
    "<br><i>&emsp;np.linalg.inv():</i> bir matrisin eleman tersini elde eder.\n",
    "<br><i>&emsp;np.reshape():</i> ic carpimda kullanilmak uzere verilen vektorun<br>&emsp;transpozunu elde eder.\n",
    "<br><i>&emsp;np.dot():</i> GPU'dan yararlanarak ic carpim islemini gerceklestirir.\n",
    "<br><i>&emsp;np.log():</i> giris uzerinde dogal logaritma islemini gerceklestirir.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f754db46-533e-4016-9538-e5005e6a35d7",
   "metadata": {},
   "source": [
    "<b>Not:</b> Kovaryans matrisleri birbirlerine esit olmadigi icin bir sonraki paragrafta ekledigim Vikipedi baglantilarindaki fonksiyonlari kullanmam gerektigini dusunmustum. Fakat o sayfalarda da bahsettigi uzere asil yapilan islem sonsal olasik dagilimi (P(C|x)) kullanilarak secim yapilmasi. Bu sebeple ders notlarindaki fonksiyonu kullanarak hata yapmadigimi dusunuyorum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8eeaf9-3145-431b-9837-6c60b5dad0e1",
   "metadata": {},
   "source": [
    "Quadratic discriminant analysis (QDA) is closely related to linear discriminant analysis (LDA), where it is assumed that the measurements from each class are normally distributed. Unlike LDA however, in QDA there is no assumption that the covariance of each of the classes is identical. When the normality assumption is true, the best possible test for the hypothesis that a given measurement is from a given class is the likelihood ratio test.\n",
    "https://en.wikipedia.org/wiki/Linear_discriminant_analysis\n",
    "https://en.wikipedia.org/wiki/Quadratic_classifier#Quadratic_discriminant_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f32d0d1-ee6d-483e-ad25-e518656a7b48",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Siniflandirici Tanimlamak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ff3f6c-4b98-467c-9aa3-06d90cad6711",
   "metadata": {},
   "source": [
    "Verilen yeni verinin hangi sinifa ait oldugunu tahmin etmek icin olabilirlik orani (likelihood test) kullanilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aebdfef-6942-4c30-9e86-7c5df23aedb3",
   "metadata": {},
   "source": [
    "Siniflandiriciyi yapmak icin karar verici fonksiyon ayni veriyi kullanarak iki sinifa da ait olan ayirt edici fonksiyonlari ayri ayri cagirir. Cikan sonuclari karsilastirarak hangi sinifa ait olduguna karar verir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75dd783a-56b8-48ae-ba62-63e9feafc099",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Classify(x,ave_matrix,cov_matrix,N,P_matrix):\n",
    "    \n",
    "    # x, expected: 1x2\n",
    "    # can be 1x(number of features)\n",
    "    \n",
    "    # ave_matrix, expected: 2x2\n",
    "    # can be (number of classes)x(number of features)\n",
    "    \n",
    "    # cov_matrix, expected: 4x2\n",
    "    # can be ((number of classes)*(number of features))x(number of features)\n",
    "    \n",
    "    # N, expected: 100\n",
    "    # can be (number of examples)\n",
    "    \n",
    "    # P_matrix, expected: 1x2\n",
    "    # can be 1x(number of classes)\n",
    "    # definition: matrix of priori probabilities of each class\n",
    "    \n",
    "    # get number of classes\n",
    "    n_class=np.size(ave_matrix,1)\n",
    "    \n",
    "    # get number of features\n",
    "    n_features=np.size(ave_matrix,0)\n",
    "    \n",
    "    # create array to hold g data\n",
    "    # (number of examples) x (number of classes)\n",
    "    g = np.zeros((1,n_class))\n",
    "    \n",
    "    # loop for finding predictions for each class\n",
    "    for i in range(n_class):\n",
    "        g[0,i]=discriminant_fnc(x, ave_matrix[i, :], cov_matrix[  (0+n_features*i): (n_features+n_features*i), : ], N, P_matrix[0,i])\n",
    "        \n",
    "    # define temporary max and update it\n",
    "    temp_max = - mt.inf\n",
    "    keep_class=0\n",
    "    # loop to find max\n",
    "    for i in range(n_class):\n",
    "        \n",
    "        temp_g=float(g[0,i])\n",
    "        #temp_g=temp_g.item()\n",
    "        #temp_g=abs(temp_g)\n",
    "        \n",
    "        # if g is bigger, update max\n",
    "        # keep class number\n",
    "        if temp_g >temp_max:\n",
    "            temp_max=temp_g\n",
    "            keep_class=i\n",
    "            \n",
    "        # else, keep the previous max\n",
    "        else:\n",
    "            temp_max=temp_max\n",
    "            \n",
    "    # return the prediction\n",
    "    return keep_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa10e26-1188-461b-a5fb-bd2b2a434d4f",
   "metadata": {},
   "source": [
    "Ilk once odevde verilen dagilimlarin parametreleri tanimlanir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dbf1f9a-b75d-405e-b97c-6db2350feacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define attributes of the distributions.\n",
    "N=100\n",
    "ave_matrix=np.array([[3,2],[5,4]])\n",
    "cov_matrix=np.array([[.5,0],[0,.5],[1,0],[0,1]])\n",
    "# priori Probabilities of classes taken to be equal\n",
    "P_c=np.array([[.5,.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a653a2-42a3-41b7-ad2c-0af48257c68d",
   "metadata": {},
   "source": [
    "Sonrasinda en basta Gauss dagilimindan orneklenerek uretilen \"samples\" verisinin her biri icin siniflandirici fonksiyonu cagirilir. Boylece her verinin siniflandirma tahmini yapilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6172d655-5727-4e73-b0a8-010b94ac2dc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONLY the first 10 predictions are printed so that output is not too long\n",
      "These are the predictions for the samples from the distribution of the first class:\n",
      "The  1 . example is predicted to belong to 1 . class.\n",
      "The  2 . example is predicted to belong to 1 . class.\n",
      "The  3 . example is predicted to belong to 1 . class.\n",
      "The  4 . example is predicted to belong to 1 . class.\n",
      "The  5 . example is predicted to belong to 1 . class.\n",
      "The  6 . example is predicted to belong to 1 . class.\n",
      "The  7 . example is predicted to belong to 1 . class.\n",
      "The  8 . example is predicted to belong to 1 . class.\n",
      "The  9 . example is predicted to belong to 1 . class.\n",
      "The  10 . example is predicted to belong to 1 . class.\n",
      "The  11 . example is predicted to belong to 1 . class.\n",
      "The  12 . example is predicted to belong to 1 . class.\n",
      "The  13 . example is predicted to belong to 1 . class.\n",
      "The  14 . example is predicted to belong to 1 . class.\n",
      "The  15 . example is predicted to belong to 1 . class.\n",
      "The  16 . example is predicted to belong to 1 . class.\n",
      "The  17 . example is predicted to belong to 1 . class.\n",
      "The  18 . example is predicted to belong to 1 . class.\n",
      "The  19 . example is predicted to belong to 1 . class.\n",
      "The  20 . example is predicted to belong to 1 . class.\n",
      "The  21 . example is predicted to belong to 1 . class.\n",
      "The  22 . example is predicted to belong to 1 . class.\n",
      "The  23 . example is predicted to belong to 1 . class.\n",
      "The  24 . example is predicted to belong to 1 . class.\n",
      "The  25 . example is predicted to belong to 1 . class.\n",
      "The  26 . example is predicted to belong to 1 . class.\n",
      "The  27 . example is predicted to belong to 1 . class.\n",
      "The  28 . example is predicted to belong to 1 . class.\n",
      "The  29 . example is predicted to belong to 1 . class.\n",
      "The  30 . example is predicted to belong to 1 . class.\n",
      "The  31 . example is predicted to belong to 1 . class.\n",
      "The  32 . example is predicted to belong to 1 . class.\n",
      "The  33 . example is predicted to belong to 1 . class.\n",
      "The  34 . example is predicted to belong to 1 . class.\n",
      "The  35 . example is predicted to belong to 1 . class.\n",
      "The  36 . example is predicted to belong to 1 . class.\n",
      "The  37 . example is predicted to belong to 2 . class.\n",
      "The  38 . example is predicted to belong to 1 . class.\n",
      "The  39 . example is predicted to belong to 1 . class.\n",
      "The  40 . example is predicted to belong to 1 . class.\n",
      "The  41 . example is predicted to belong to 1 . class.\n",
      "The  42 . example is predicted to belong to 1 . class.\n",
      "The  43 . example is predicted to belong to 1 . class.\n",
      "The  44 . example is predicted to belong to 1 . class.\n",
      "The  45 . example is predicted to belong to 1 . class.\n",
      "The  46 . example is predicted to belong to 1 . class.\n",
      "The  47 . example is predicted to belong to 1 . class.\n",
      "The  48 . example is predicted to belong to 1 . class.\n",
      "The  49 . example is predicted to belong to 1 . class.\n",
      "The  50 . example is predicted to belong to 1 . class.\n",
      "The  51 . example is predicted to belong to 1 . class.\n",
      "The  52 . example is predicted to belong to 1 . class.\n",
      "The  53 . example is predicted to belong to 1 . class.\n",
      "The  54 . example is predicted to belong to 1 . class.\n",
      "The  55 . example is predicted to belong to 1 . class.\n",
      "The  56 . example is predicted to belong to 1 . class.\n",
      "The  57 . example is predicted to belong to 1 . class.\n",
      "The  58 . example is predicted to belong to 1 . class.\n",
      "The  59 . example is predicted to belong to 1 . class.\n",
      "The  60 . example is predicted to belong to 1 . class.\n",
      "The  61 . example is predicted to belong to 1 . class.\n",
      "The  62 . example is predicted to belong to 1 . class.\n",
      "The  63 . example is predicted to belong to 1 . class.\n",
      "The  64 . example is predicted to belong to 2 . class.\n",
      "The  65 . example is predicted to belong to 1 . class.\n",
      "The  66 . example is predicted to belong to 1 . class.\n",
      "The  67 . example is predicted to belong to 1 . class.\n",
      "The  68 . example is predicted to belong to 1 . class.\n",
      "The  69 . example is predicted to belong to 1 . class.\n",
      "The  70 . example is predicted to belong to 2 . class.\n",
      "The  71 . example is predicted to belong to 1 . class.\n",
      "The  72 . example is predicted to belong to 1 . class.\n",
      "The  73 . example is predicted to belong to 1 . class.\n",
      "The  74 . example is predicted to belong to 1 . class.\n",
      "The  75 . example is predicted to belong to 1 . class.\n",
      "The  76 . example is predicted to belong to 1 . class.\n",
      "The  77 . example is predicted to belong to 1 . class.\n",
      "The  78 . example is predicted to belong to 1 . class.\n",
      "The  79 . example is predicted to belong to 1 . class.\n",
      "The  80 . example is predicted to belong to 1 . class.\n",
      "The  81 . example is predicted to belong to 1 . class.\n",
      "The  82 . example is predicted to belong to 1 . class.\n",
      "The  83 . example is predicted to belong to 1 . class.\n",
      "The  84 . example is predicted to belong to 1 . class.\n",
      "The  85 . example is predicted to belong to 1 . class.\n",
      "The  86 . example is predicted to belong to 1 . class.\n",
      "The  87 . example is predicted to belong to 2 . class.\n",
      "The  88 . example is predicted to belong to 1 . class.\n",
      "The  89 . example is predicted to belong to 1 . class.\n",
      "The  90 . example is predicted to belong to 1 . class.\n",
      "The  91 . example is predicted to belong to 1 . class.\n",
      "The  92 . example is predicted to belong to 1 . class.\n",
      "The  93 . example is predicted to belong to 1 . class.\n",
      "The  94 . example is predicted to belong to 1 . class.\n",
      "The  95 . example is predicted to belong to 1 . class.\n",
      "The  96 . example is predicted to belong to 1 . class.\n",
      "The  97 . example is predicted to belong to 1 . class.\n",
      "The  98 . example is predicted to belong to 1 . class.\n",
      "The  99 . example is predicted to belong to 1 . class.\n",
      "The  100 . example is predicted to belong to 1 . class.\n"
     ]
    }
   ],
   "source": [
    "# hold the predictions\n",
    "\n",
    "prediction_holder = np.zeros(N)\n",
    "\n",
    "# to input only one line of the sample, get \"samples_c1[i,:]\"\"\n",
    "for i in range(N):\n",
    "    prediction_holder[i] = Classify(samples_c1[i,:],ave_matrix,cov_matrix,N,P_c)\n",
    "    #print(prediction_holder)\n",
    "    \n",
    "# print description\n",
    "print('ONLY the first 10 predictions are printed so that output is not too long')\n",
    "print('These are the predictions for the samples from the distribution of the first class:')\n",
    "# print predictions\n",
    "for i in range(int((np.size(prediction_holder))/1)):\n",
    "    print('The ', (i+1), '. example is predicted to belong to', (1+int(prediction_holder[i])),'. class.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5ddaa8a-79d5-4734-9b14-c82beda57d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the predictions for the samples from the distribution of the second class:\n",
      "The  1 . example is predicted to belong to 2 . class.\n",
      "The  2 . example is predicted to belong to 2 . class.\n",
      "The  3 . example is predicted to belong to 2 . class.\n",
      "The  4 . example is predicted to belong to 2 . class.\n",
      "The  5 . example is predicted to belong to 2 . class.\n",
      "The  6 . example is predicted to belong to 2 . class.\n",
      "The  7 . example is predicted to belong to 2 . class.\n",
      "The  8 . example is predicted to belong to 2 . class.\n",
      "The  9 . example is predicted to belong to 2 . class.\n",
      "The  10 . example is predicted to belong to 2 . class.\n",
      "The  11 . example is predicted to belong to 2 . class.\n",
      "The  12 . example is predicted to belong to 2 . class.\n",
      "The  13 . example is predicted to belong to 2 . class.\n",
      "The  14 . example is predicted to belong to 2 . class.\n",
      "The  15 . example is predicted to belong to 2 . class.\n",
      "The  16 . example is predicted to belong to 2 . class.\n",
      "The  17 . example is predicted to belong to 2 . class.\n",
      "The  18 . example is predicted to belong to 2 . class.\n",
      "The  19 . example is predicted to belong to 2 . class.\n",
      "The  20 . example is predicted to belong to 2 . class.\n",
      "The  21 . example is predicted to belong to 2 . class.\n",
      "The  22 . example is predicted to belong to 2 . class.\n",
      "The  23 . example is predicted to belong to 2 . class.\n",
      "The  24 . example is predicted to belong to 2 . class.\n",
      "The  25 . example is predicted to belong to 2 . class.\n",
      "The  26 . example is predicted to belong to 2 . class.\n",
      "The  27 . example is predicted to belong to 2 . class.\n",
      "The  28 . example is predicted to belong to 2 . class.\n",
      "The  29 . example is predicted to belong to 2 . class.\n",
      "The  30 . example is predicted to belong to 2 . class.\n",
      "The  31 . example is predicted to belong to 2 . class.\n",
      "The  32 . example is predicted to belong to 2 . class.\n",
      "The  33 . example is predicted to belong to 2 . class.\n",
      "The  34 . example is predicted to belong to 2 . class.\n",
      "The  35 . example is predicted to belong to 2 . class.\n",
      "The  36 . example is predicted to belong to 2 . class.\n",
      "The  37 . example is predicted to belong to 1 . class.\n",
      "The  38 . example is predicted to belong to 2 . class.\n",
      "The  39 . example is predicted to belong to 2 . class.\n",
      "The  40 . example is predicted to belong to 2 . class.\n",
      "The  41 . example is predicted to belong to 2 . class.\n",
      "The  42 . example is predicted to belong to 2 . class.\n",
      "The  43 . example is predicted to belong to 2 . class.\n",
      "The  44 . example is predicted to belong to 2 . class.\n",
      "The  45 . example is predicted to belong to 2 . class.\n",
      "The  46 . example is predicted to belong to 2 . class.\n",
      "The  47 . example is predicted to belong to 2 . class.\n",
      "The  48 . example is predicted to belong to 2 . class.\n",
      "The  49 . example is predicted to belong to 2 . class.\n",
      "The  50 . example is predicted to belong to 2 . class.\n",
      "The  51 . example is predicted to belong to 2 . class.\n",
      "The  52 . example is predicted to belong to 2 . class.\n",
      "The  53 . example is predicted to belong to 2 . class.\n",
      "The  54 . example is predicted to belong to 2 . class.\n",
      "The  55 . example is predicted to belong to 2 . class.\n",
      "The  56 . example is predicted to belong to 2 . class.\n",
      "The  57 . example is predicted to belong to 2 . class.\n",
      "The  58 . example is predicted to belong to 2 . class.\n",
      "The  59 . example is predicted to belong to 2 . class.\n",
      "The  60 . example is predicted to belong to 2 . class.\n",
      "The  61 . example is predicted to belong to 2 . class.\n",
      "The  62 . example is predicted to belong to 2 . class.\n",
      "The  63 . example is predicted to belong to 2 . class.\n",
      "The  64 . example is predicted to belong to 2 . class.\n",
      "The  65 . example is predicted to belong to 2 . class.\n",
      "The  66 . example is predicted to belong to 2 . class.\n",
      "The  67 . example is predicted to belong to 2 . class.\n",
      "The  68 . example is predicted to belong to 2 . class.\n",
      "The  69 . example is predicted to belong to 2 . class.\n",
      "The  70 . example is predicted to belong to 1 . class.\n",
      "The  71 . example is predicted to belong to 2 . class.\n",
      "The  72 . example is predicted to belong to 2 . class.\n",
      "The  73 . example is predicted to belong to 2 . class.\n",
      "The  74 . example is predicted to belong to 2 . class.\n",
      "The  75 . example is predicted to belong to 2 . class.\n",
      "The  76 . example is predicted to belong to 2 . class.\n",
      "The  77 . example is predicted to belong to 2 . class.\n",
      "The  78 . example is predicted to belong to 1 . class.\n",
      "The  79 . example is predicted to belong to 2 . class.\n",
      "The  80 . example is predicted to belong to 2 . class.\n",
      "The  81 . example is predicted to belong to 2 . class.\n",
      "The  82 . example is predicted to belong to 1 . class.\n",
      "The  83 . example is predicted to belong to 2 . class.\n",
      "The  84 . example is predicted to belong to 1 . class.\n",
      "The  85 . example is predicted to belong to 2 . class.\n",
      "The  86 . example is predicted to belong to 2 . class.\n",
      "The  87 . example is predicted to belong to 2 . class.\n",
      "The  88 . example is predicted to belong to 2 . class.\n",
      "The  89 . example is predicted to belong to 2 . class.\n",
      "The  90 . example is predicted to belong to 2 . class.\n",
      "The  91 . example is predicted to belong to 2 . class.\n",
      "The  92 . example is predicted to belong to 2 . class.\n",
      "The  93 . example is predicted to belong to 2 . class.\n",
      "The  94 . example is predicted to belong to 2 . class.\n",
      "The  95 . example is predicted to belong to 2 . class.\n",
      "The  96 . example is predicted to belong to 2 . class.\n",
      "The  97 . example is predicted to belong to 2 . class.\n",
      "The  98 . example is predicted to belong to 2 . class.\n",
      "The  99 . example is predicted to belong to 2 . class.\n",
      "The  100 . example is predicted to belong to 2 . class.\n"
     ]
    }
   ],
   "source": [
    "for i in range(N):\n",
    "    prediction_holder[i] = Classify(samples_c2[i,:],ave_matrix,cov_matrix,N,P_c)\n",
    "    #print(prediction_holder)\n",
    "    \n",
    "# print description\n",
    "print('These are the predictions for the samples from the distribution of the second class:')\n",
    "# print predictions\n",
    "for i in range(int((np.size(prediction_holder))/1)):\n",
    "    print('The ', (i+1), '. example is predicted to belong to', (1+int(prediction_holder[i])),'. class.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bc8fcf-26d2-4ed8-9120-42f61e9f3b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
